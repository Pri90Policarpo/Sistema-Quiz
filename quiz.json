{"registros": {"1": {"type": "quiz", "text": "Your company has decided to make a major revision of their API in order to create better experiences for their developers. They need to keep the old version of the API available and deployable, while allowing new customers and testers to try out the new API. They want to keep the same SSL and DNS records in place to serve both APIs.\nWhat should they do?", "options": [{"text": "A. Configure a new load balancer for the new version of the API", "explanation": "Configuring a new load balancer would require separate SSL and DNS records for each load balancer, which contradicts the requirement to keep the same SSL and DNS records.", "correct": false}, {"text": "B. Reconfigure old clients to use a new endpoint for the new API", "explanation": "Reconfiguring old clients to use a new endpoint would disrupt existing clients and negate the need to keep the same SSL and DNS records.", "correct": false}, {"text": "C. Have the old API forward traffic to the new API based on the path", "explanation": "This approach involves adding unnecessary complexity to the old API, and it does not leverage the capabilities of load balancers to manage traffic efficiently between different API versions.", "correct": false}, {"text": "D. Use separate backend pools for each API path behind the load balancer", "explanation": "This is the best solution as it allows the load balancer to route traffic to the appropriate backend pool based on the API path. This method keeps the same SSL and DNS records while enabling both versions of the API to be served from the same endpoint. It also provides a clean separation of concerns, allowing each API version to be managed independently.", "correct": true}]}, "2": {"type": "quiz", "text": "Your company plans to migrate a multi-petabyte data set to the cloud. The data set must be available 24hrs a day. Your business analysts have experience only with using a SQL interface.\nHow should you store the data to optimize it for ease of analysis?", "options": [{"text": "A. Load data into Google BigQuery", "explanation": " Google BigQuery is a fully managed, serverless, highly scalable data warehouse that supports SQL queries. It is designed for analyzing large datasets quickly and efficiently. BigQuery can handle multi-petabyte datasets and offers 24/7 availability. It is optimized for ease of analysis with its support for standard SQL, which aligns perfectly with the business analysts' experience.", "correct": true}, {"text": "B. Insert data into Google Cloud SQL", "explanation": "Google Cloud SQL is a managed relational database service that supports SQL, but it is not designed to handle multi-petabyte datasets efficiently. It is more suitable for smaller-scale applications and workloads. For extremely large datasets, performance and scalability would be significant concerns.", "correct": false}, {"text": "C. Put flat files into Google Cloud Storage", "explanation": "Google Cloud Storage is an object storage service ideal for storing large amounts of unstructured data, such as flat files. While it can store multi-petabyte datasets and offers high availability, it is not optimized for SQL-based analysis. To analyze the data, you would need to load it into a service like BigQuery or a similar database, adding an extra step.", "correct": false}, {"text": "D. Stream data into Google Cloud Datastore", "explanation": "Google Cloud Datastore is a NoSQL document database designed for web and mobile applications. It does not natively support SQL queries and is not optimized for multi-petabyte datasets or traditional analytical workloads. Using Datastore would complicate the analysis process for business analysts accustomed to SQL.", "correct": false}]}, "3": {"type": "quiz", "text": "The operations manager asks you for a list of recommended practices that she should consider when migrating a J2EE application to the cloud.\nWhich three practices should you recommend? (Choose three.)\n", "options": [{"text": "A. Port the application code to run on Google App Engine", "explanation": "Google App Engine is a fully managed serverless platform that allows you to deploy and run applications without managing the underlying infrastructure. Migrating a J2EE application to App Engine can take advantage of its scalability, load balancing, and integrated development environment.", "correct": true}, {"text": "B. Integrate Cloud Dataflow into the application to capture real-time metrics", "explanation": "Cloud Dataflow is primarily used for stream and batch data processing. While it is a powerful tool for real-time data analytics, it is not directly relevant to the migration of a J2EE application to the cloud. Capturing real-time metrics is important, but there are more suitable tools for application monitoring and logging, such as Stackdriver (now part of Google Cloud's Operations suite).", "correct": false}, {"text": "C. Instrument the application with a monitoring tool like Stackdriver Debugger", "explanation": "Monitoring tools are essential for tracking the performance, availability, and reliability of applications in the cloud. Stackdriver Debugger (now part of Google Cloud's Operations suite) provides real-time insights into the application\u2019s behavior, which is crucial for managing and optimizing the application post-migration.", "correct": true}, {"text": "D. Select an automation framework to reliably provision the cloud infrastructure", "explanation": "Using an automation framework (like Terraform or Google Deployment Manager) ensures that the cloud infrastructure is provisioned reliably and consistently. Automation helps reduce human error, improves repeatability, and allows for version control of infrastructure configurations.", "correct": true}, {"text": "E. Deploy a continuous integration tool with automated testing in a staging environment", "explanation": "While continuous integration and automated testing are best practices for software development and deployment, they are not specific to the migration of a J2EE application to the cloud. This practice is more about the ongoing development process rather than the migration itself.", "correct": false}, {"text": "F. Migrate from MySQL to a managed NoSQL database like Google Cloud Datastore or Bigtable", "explanation": "Migrating from MySQL to a managed NoSQL database is a significant architectural change and may not be necessary or appropriate for a J2EE application. The choice of database should be based on the specific needs of the application. If the application is already using a relational database, it might be more straightforward to migrate to a managed relational database service like Google Cloud SQL.", "correct": false}]}, "4": {"type": "quiz", "text": "A news feed web service has the following code running on Google App Engine. During peak load, users report that they can see news articles they already viewed.\nWhat is the most likely cause of this problem?\n\n```\nimport news\nfrom flask import Flask, redirect, request \nfrom flask.ext.api import status \nfrom google.appengine.api import users\n\napp = Flask (_name_)\ngessiong = ()\n\n@app. route (\"/\") def homepage () :\n\t\t\t\tuser = users.get_current_user ()\n\t\t\t\tif not user:\n\t\t\t\t\t\t\t\treturn \"Invalid login\", status.HTTP_401_UNAUTHORIZED\n\t\t\t\tif user not in sessions:\n\t\t\t\t\t\t\t\tsessions (user] = {\"viewed\": []}|\n\t\t\t\t\n\t\t\t\tnews_articles = news.get_new_news (user, sessions [user][\"viewed\" ])\n\t\t\t\tsessions (user] [\"viewed\"] +- In[\"id\"] for n in news_articles\uff3d\n\n\t\t\t\treturn news. render (news_articles)\n\nif __name__ == \"_main\":\n\t\t\t\tapp.run()\n```", "options": [{"text": "A. The session variable is local to just a single instance Most Voted", "explanation": "This is the correct answer because it directly addresses the issue of sessions being local to each instance and not shared across instances, leading to the observed problem.", "correct": true}, {"text": "B. The session variable is being overwritten in Cloud Datastore", "explanation": "This is incorrect because the code does not use Cloud Datastore for storing session information.", "correct": false}, {"text": "C. The URL of the API needs to be modified to prevent caching", "explanation": "This is incorrect because the issue is related to session handling, not caching of API responses.", "correct": false}, {"text": "D. The HTTP Expires header needs to be set to -1 stop caching", "explanation": " This is incorrect because the issue is related to session management, not HTTP caching headers.", "correct": false}]}, "5": {"type": "quiz", "text": "An application development team believes their current logging tool will not meet their needs for their new cloud-based product. They want a better tool to capture errors and help them analyze their historical log data. You want to help them find a solution that meets their needs.\nWhat should you do?", "options": [{"text": "A. Direct them to download and install the Google StackDriver logging agent", "explanation": "This answer might be too presumptive. The team hasn't yet defined their specific requirements for the logging tool, and while Google StackDriver (now part of Google Cloud's Operations suite) is a powerful tool, it may not necessarily meet their unique needs without first understanding those needs.", "correct": false}, {"text": "B. Send them a list of online resources about logging best practices", "explanation": "While educating the team on logging best practices is beneficial, it doesn't directly address their immediate need to find a better tool for capturing errors and analyzing log data. This option lacks the hands-on support that the team may require to find a solution.", "correct": false}, {"text": "C. Help them define their requirements and assess viable logging tools", "explanation": "This is the most appropriate approach because it ensures that the team first understands their specific needs and requirements. Once these are defined, they can then evaluate different logging tools against these requirements to find the most suitable one. This method is thorough and ensures that the chosen tool will effectively meet their needs.", "correct": true}, {"text": "D. Help them upgrade their current tool to take advantage of any new features", "explanation": "Upgrading the current tool could be a viable solution, but it assumes that the existing tool, with new features, can meet their needs. Without first understanding their specific requirements, this approach might not solve their problems and could potentially lead to wasted effort if the current tool remains inadequate even after an upgrade.", "correct": false}]}}}